{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the model to be used\n",
    "COCO and MPI are body pose estimation model. COCO has 18 points and MPI has 15 points as output.\n",
    "\n",
    "HAND is hand keypoints estimation model. It has 22 points as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = \"MPI\"\n",
    "\n",
    "if MODE == \"COCO\":\n",
    "    protoFile = \"pose/coco/pose_deploy_linevec.prototxt\"\n",
    "    weightsFile = \"pose/coco/pose_iter_440000.caffemodel\"\n",
    "    nPoints = 18\n",
    "    POSE_PAIRS = [ [1,0],[1,2],[1,5],[2,3],[3,4],[5,6],[6,7],[1,8],[8,9],[9,10],[1,11],[11,12],[12,13],[0,14],[0,15],[14,16],[15,17]]\n",
    "\n",
    "elif MODE == \"MPI\" :\n",
    "    protoFile = \"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n",
    "    weightsFile = \"pose/mpi/pose_iter_160000.caffemodel\"\n",
    "    nPoints = 15\n",
    "    POSE_PAIRS = [[0,1], [1,2], [2,3], [3,4], [1,5], [5,6], [6,7], [1,14], [14,8], [8,9], [9,10], [14,11], [11,12], [12,13] ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Empty list to store the detected keypoints\n",
    "def show_keypoints(frame):\n",
    "    \n",
    "    frameCopy = np.copy(frame)\n",
    "    frameWidth = frame.shape[1]\n",
    "    frameHeight = frame.shape[0]\n",
    "    threshold = 0.1\n",
    "    \n",
    "    inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n",
    "                          (0, 0, 0), swapRB=False, crop=False)\n",
    "\n",
    "    net.setInput(inpBlob)\n",
    "\n",
    "    output = net.forward()\n",
    "    H = output.shape[2]\n",
    "    W = output.shape[3]\n",
    "    \n",
    "    points = []\n",
    "    \n",
    "    for i in range(nPoints):\n",
    "        # confidence map of corresponding body's part.\n",
    "        probMap = output[0, i, :, :]\n",
    "    \n",
    "        # Find global maxima of the probMap.\n",
    "        minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n",
    "        \n",
    "        # Scale the point to fit on the original image\n",
    "        x = (frameWidth * point[0]) / W\n",
    "        y = (frameHeight * point[1]) / H\n",
    "    \n",
    "        if prob > threshold : \n",
    "            cv2.circle(frameCopy, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "            cv2.putText(frameCopy, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, lineType=cv2.LINE_AA)\n",
    "            cv2.circle(frame, (int(x), int(y)), 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n",
    "    \n",
    "            # Add the point to the list if the probability is greater than the threshold\n",
    "            points.append((int(x), int(y)))\n",
    "        else :\n",
    "            points.append(None)\n",
    "    \n",
    "    # Draw Skeleton\n",
    "    for pair in POSE_PAIRS:\n",
    "        partA = pair[0]\n",
    "        partB = pair[1]\n",
    "    \n",
    "        if points[partA] and points[partB]:\n",
    "            cv2.line(frame, points[partA], points[partB], (0, 255, 255), 3)\n",
    "    \n",
    "    return frame, points\n",
    "#     plt.figure(figsize=[10,10])\n",
    "#     plt.imshow(cv2.cvtColor(frameCopy, cv2.COLOR_BGR2RGB))\n",
    "#     plt.figure(figsize=[10,10])\n",
    "#     plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_path, output_path):\n",
    "    \n",
    "    video_reader = cv2.VideoCapture(input_path)\n",
    "    fps = int(video_reader.get(cv2.CAP_PROP_FPS))\n",
    "    height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    \n",
    "    if output_path:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    \n",
    "        video_writer = cv2.VideoWriter(\n",
    "            output_path, fourcc, fps, \n",
    "            (height, width))\n",
    "    i = 0\n",
    "    res_points = []\n",
    "    with tqdm(total=int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT)), position=0, leave=True) as pbar:\n",
    "        while (video_reader.isOpened()):\n",
    "            ret, frame = video_reader.read()\n",
    "            if ret == True:\n",
    "                i+=1\n",
    "                \n",
    "                frame, points = show_keypoints(frame)\n",
    "                res_points.append(points)\n",
    "                \n",
    "                if output_path:\n",
    "                    video_writer.write(frame)\n",
    "        \n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "                \n",
    "                pbar.update(1)\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "            \n",
    "        if output_path:\n",
    "            video_reader.release()\n",
    "            video_writer.release()\n",
    "            cv2.destroyAllWindows()\n",
    "    return res_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out/signer14_sample144_color.mp4\n",
      "512\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5798822b304498a997b55a1b34884d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dir = 'test'\n",
    "out_dir = 'out'\n",
    "if not os.path.isdir(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "for video_name in os.listdir(input_dir):\n",
    "    print (os.path.join(out_dir, video_name))\n",
    "    res_points = process_video(os.path.join(input_dir, video_name), os.path.join(out_dir, video_name))\n",
    "    \n",
    "    with open(os.path.join(out_dir, video_name.split('.')[0] + '.txt'), \"wb\") as fp: \n",
    "        pickle.dump(res_points, fp)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
